{
 "cells": [
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "302b430103d02bbe",
    "outputId": "baaf358c-4e61-453a-b1f6-262d1a218350",
    "ExecuteTime": {
     "end_time": "2024-11-02T21:16:10.566186Z",
     "start_time": "2024-11-02T21:16:10.180295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "# Load the text from a local file\n",
    "def load_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "# Load the text from a URL\n",
    "def load_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    text = response.text.replace('\\r\\n', '\\n')  # Normalize line endings\n",
    "    return text\n",
    "\n",
    "# Count unique characters in the text\n",
    "def count_unique_chars(text):\n",
    "    unique_chars = set(text)\n",
    "    # Num of unique characters\n",
    "    vocab_size = len(unique_chars)\n",
    "    return vocab_size, unique_chars\n",
    "\n",
    "# List of file paths or URLs\n",
    "local_file_1 = 'pg100.txt'\n",
    "local_file_2 = 'pg2600.txt'\n",
    "local_file_3 = 'pg766.txt'\n",
    "url_file_1 = 'https://www.gutenberg.org/cache/epub/100/pg100.txt'\n",
    "url_file_2 = 'https://www.gutenberg.org/cache/epub/2600/pg2600.txt'\n",
    "url_file_3 = 'https://www.gutenberg.org/cache/epub/766/pg766.txt'\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    file_path_list = [url_file_1, url_file_2, url_file_3]\n",
    "else:\n",
    "    file_path_list = [local_file_1, local_file_2, local_file_3]\n",
    "text_list = []\n",
    "vocab_size_list = []\n",
    "unique_chars_list = []\n",
    "\n",
    "for file_path in file_path_list:\n",
    "    if file_path.startswith('http'):\n",
    "        print(f'Loading text from URL: {file_path}')\n",
    "        text = load_text_from_url(file_path)\n",
    "    else:\n",
    "        print(f'Loading text from file: {file_path}')\n",
    "        text = load_text_from_file(file_path)\n",
    "    vocab_size, unique_chars = count_unique_chars(text)\n",
    "    text_list.append(text)\n",
    "    vocab_size_list.append(vocab_size)\n",
    "    unique_chars_list.append(unique_chars)\n",
    "\n",
    "print(f'Vocabulary size for each text: {vocab_size_list}')\n",
    "print(f'Unique characters for each text: {unique_chars_list}')\n",
    "print(f'Example unique characters: {unique_chars_list[0]}')"
   ],
   "id": "302b430103d02bbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text from file: pg100.txt\n",
      "Loading text from file: pg2600.txt\n",
      "Loading text from file: pg766.txt\n",
      "Vocabulary size for each text: [107, 112, 90]\n",
      "Unique characters for each text: [{'K', 'J', '3', '—', '1', 'w', 'S', \"'\", 'À', '7', 'Q', 'k', '/', 'h', '’', 'F', 'L', '8', 'R', 'a', '%', 'ë', 'o', 'à', 'Æ', '\\n', '“', 'r', 'O', 'G', 'æ', '\\t', 'H', 'â', 'U', 'X', 'b', 'l', 'œ', '$', 'g', 'y', '6', '0', '‘', '™', 'N', 'É', 'A', '”', '…', 'E', 's', '_', '?', 'V', '.', 'm', '!', 'M', 'é', '[', '2', 'z', 'i', 'Y', 'D', 'Ç', '&', 'Z', 'j', 't', 'd', 'f', 'C', ')', '\\ufeff', ' ', ',', '9', 'ê', 'n', '(', 'î', 'P', 'W', '-', '4', 'c', 'v', '5', '•', 'q', 'ç', 'I', 'p', ';', ':', 'x', 'T', 'B', 'è', 'u', 'e', '#', '*', ']'}, {'K', 'Á', 'J', '3', '—', '1', 'á', 'w', 'S', 'À', '7', 'ô', 'ï', 'Q', 'k', '/', 'h', '’', 'F', 'L', '8', 'ú', 'R', 'a', '%', 'ë', 'o', 'à', '\\n', 'ý', '“', 'r', 'O', 'G', 'æ', 'H', 'â', 'U', 'X', 'b', 'l', 'ö', 'ü', 'í', 'œ', '$', 'g', 'y', '6', '0', '‘', '™', 'N', 'É', 'A', '”', '=', 'E', 's', '?', 'V', '.', 'm', '!', 'M', 'é', '[', '2', 'z', 'i', 'ä', 'Y', 'D', 'Z', 'j', 't', 'd', 'f', 'C', ')', '\\ufeff', ' ', ',', '9', 'ê', 'n', '(', 'î', 'P', 'W', '-', '4', 'c', 'v', '5', '•', 'q', 'ç', 'I', 'p', 'ó', ';', ':', 'x', 'T', 'B', 'è', 'u', 'e', '#', '*', ']'}, {'K', 'J', '3', '—', '1', 'w', 'S', '7', 'Q', 'k', '/', 'h', '’', 'F', 'L', '8', 'R', 'a', '%', 'o', '\\n', '“', 'r', 'O', 'G', 'H', 'U', 'X', 'b', 'l', '$', 'g', 'y', '6', '0', '‘', '™', 'N', 'A', '”', 'E', 's', '_', '?', 'V', '.', 'm', '!', 'M', '[', '2', 'z', 'i', 'Y', 'D', '&', 'Z', 'j', 't', 'd', 'f', 'C', ')', '\\ufeff', ' ', ',', '9', 'n', '(', 'P', '-', 'W', '4', 'c', 'v', '5', '•', 'q', 'I', 'p', ';', ':', 'x', 'T', 'B', 'u', 'e', '#', '*', ']'}]\n",
      "Example unique characters: {'K', 'J', '3', '—', '1', 'w', 'S', \"'\", 'À', '7', 'Q', 'k', '/', 'h', '’', 'F', 'L', '8', 'R', 'a', '%', 'ë', 'o', 'à', 'Æ', '\\n', '“', 'r', 'O', 'G', 'æ', '\\t', 'H', 'â', 'U', 'X', 'b', 'l', 'œ', '$', 'g', 'y', '6', '0', '‘', '™', 'N', 'É', 'A', '”', '…', 'E', 's', '_', '?', 'V', '.', 'm', '!', 'M', 'é', '[', '2', 'z', 'i', 'Y', 'D', 'Ç', '&', 'Z', 'j', 't', 'd', 'f', 'C', ')', '\\ufeff', ' ', ',', '9', 'ê', 'n', '(', 'î', 'P', 'W', '-', '4', 'c', 'v', '5', '•', 'q', 'ç', 'I', 'p', ';', ':', 'x', 'T', 'B', 'è', 'u', 'e', '#', '*', ']'}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "b1ba040297cb3e10",
    "ExecuteTime": {
     "end_time": "2024-11-02T21:16:11.349189Z",
     "start_time": "2024-11-02T21:16:11.333558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Compare unique characters from local and URL text files\n",
    "# local_file_path = 'pg2600.txt'\n",
    "# url_file_path = 'https://www.gutenberg.org/cache/epub/2600/pg2600.txt'\n",
    "#\n",
    "# local_text = load_text_from_file(local_file_path)\n",
    "# local_vocab_size, local_unique_chars = count_unique_chars(local_text)\n",
    "# url_text = load_text_from_url(url_file_path)\n",
    "# url_vocab_size, url_unique_chars = count_unique_chars(url_text)\n",
    "#\n",
    "# # Find the extra character(s)\n",
    "# extra_chars_in_url = url_unique_chars - local_unique_chars\n",
    "# extra_chars_in_local = local_unique_chars - url_unique_chars\n",
    "# print(f'Extra characters in URL text: {extra_chars_in_url}')\n",
    "# print(f'Extra characters in local text: {extra_chars_in_local}')"
   ],
   "id": "b1ba040297cb3e10",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e595766dd8deb1b",
    "outputId": "e4bba092-0ed1-4fb8-f5bb-712821c6766a",
    "ExecuteTime": {
     "end_time": "2024-11-02T21:16:11.898453Z",
     "start_time": "2024-11-02T21:16:11.882829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a dictionary to map characters to indices and vice-versa\n",
    "def create_char_mappings(unique_chars):\n",
    "    char_to_index = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "    index_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "    return char_to_index, index_to_char\n",
    "\n",
    "vocab_size, unique_chars = vocab_size_list[0], unique_chars_list[0]\n",
    "char_to_index, index_to_char = create_char_mappings(unique_chars)\n",
    "\n",
    "print(f\"Character to index mapping for first text: {char_to_index}\")\n",
    "print(f\"Index to character mapping for first text: {index_to_char}\")"
   ],
   "id": "9e595766dd8deb1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character to index mapping for first text: {'K': 0, 'J': 1, '3': 2, '—': 3, '1': 4, 'w': 5, 'S': 6, \"'\": 7, 'À': 8, '7': 9, 'Q': 10, 'k': 11, '/': 12, 'h': 13, '’': 14, 'F': 15, 'L': 16, '8': 17, 'R': 18, 'a': 19, '%': 20, 'ë': 21, 'o': 22, 'à': 23, 'Æ': 24, '\\n': 25, '“': 26, 'r': 27, 'O': 28, 'G': 29, 'æ': 30, '\\t': 31, 'H': 32, 'â': 33, 'U': 34, 'X': 35, 'b': 36, 'l': 37, 'œ': 38, '$': 39, 'g': 40, 'y': 41, '6': 42, '0': 43, '‘': 44, '™': 45, 'N': 46, 'É': 47, 'A': 48, '”': 49, '…': 50, 'E': 51, 's': 52, '_': 53, '?': 54, 'V': 55, '.': 56, 'm': 57, '!': 58, 'M': 59, 'é': 60, '[': 61, '2': 62, 'z': 63, 'i': 64, 'Y': 65, 'D': 66, 'Ç': 67, '&': 68, 'Z': 69, 'j': 70, 't': 71, 'd': 72, 'f': 73, 'C': 74, ')': 75, '\\ufeff': 76, ' ': 77, ',': 78, '9': 79, 'ê': 80, 'n': 81, '(': 82, 'î': 83, 'P': 84, 'W': 85, '-': 86, '4': 87, 'c': 88, 'v': 89, '5': 90, '•': 91, 'q': 92, 'ç': 93, 'I': 94, 'p': 95, ';': 96, ':': 97, 'x': 98, 'T': 99, 'B': 100, 'è': 101, 'u': 102, 'e': 103, '#': 104, '*': 105, ']': 106}\n",
      "Index to character mapping for first text: {0: 'K', 1: 'J', 2: '3', 3: '—', 4: '1', 5: 'w', 6: 'S', 7: \"'\", 8: 'À', 9: '7', 10: 'Q', 11: 'k', 12: '/', 13: 'h', 14: '’', 15: 'F', 16: 'L', 17: '8', 18: 'R', 19: 'a', 20: '%', 21: 'ë', 22: 'o', 23: 'à', 24: 'Æ', 25: '\\n', 26: '“', 27: 'r', 28: 'O', 29: 'G', 30: 'æ', 31: '\\t', 32: 'H', 33: 'â', 34: 'U', 35: 'X', 36: 'b', 37: 'l', 38: 'œ', 39: '$', 40: 'g', 41: 'y', 42: '6', 43: '0', 44: '‘', 45: '™', 46: 'N', 47: 'É', 48: 'A', 49: '”', 50: '…', 51: 'E', 52: 's', 53: '_', 54: '?', 55: 'V', 56: '.', 57: 'm', 58: '!', 59: 'M', 60: 'é', 61: '[', 62: '2', 63: 'z', 64: 'i', 65: 'Y', 66: 'D', 67: 'Ç', 68: '&', 69: 'Z', 70: 'j', 71: 't', 72: 'd', 73: 'f', 74: 'C', 75: ')', 76: '\\ufeff', 77: ' ', 78: ',', 79: '9', 80: 'ê', 81: 'n', 82: '(', 83: 'î', 84: 'P', 85: 'W', 86: '-', 87: '4', 88: 'c', 89: 'v', 90: '5', 91: '•', 92: 'q', 93: 'ç', 94: 'I', 95: 'p', 96: ';', 97: ':', 98: 'x', 99: 'T', 100: 'B', 101: 'è', 102: 'u', 103: 'e', 104: '#', 105: '*', 106: ']'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cff240b4b6efa2ea",
    "outputId": "6b2b808a-d632-4e34-e632-cadd9f71be6e",
    "ExecuteTime": {
     "end_time": "2024-11-02T21:16:12.448122Z",
     "start_time": "2024-11-02T21:16:12.271888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# One-hot encode a character based on the character index\n",
    "def one_hot_encode(char, char_to_index, vocab_size):\n",
    "    one_hot_vector = np.zeros(vocab_size)\n",
    "    one_hot_vector[char_to_index[char]] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "test_char_a = 'a'\n",
    "one_hot_vector = one_hot_encode(test_char_a, char_to_index, vocab_size)\n",
    "print(f\"One-hot encoding for '{test_char_a}': {one_hot_vector}\")"
   ],
   "id": "cff240b4b6efa2ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding for 'a': [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ac26dff8806f1e0",
    "outputId": "2b139668-1682-45d1-aaf9-029a8f729b6f",
    "ExecuteTime": {
     "end_time": "2024-11-02T21:16:12.688677Z",
     "start_time": "2024-11-02T21:16:12.673050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample a short portion from the first book\n",
    "text = text_list[0][60000:61000]\n",
    "print(text)"
   ],
   "id": "5ac26dff8806f1e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ill:\n",
      "Some in their hawks and hounds, some in their horse.\n",
      "And every humour hath his adjunct pleasure,\n",
      "Wherein it finds a joy above the rest,\n",
      "But these particulars are not my measure,\n",
      "All these I better in one general best.\n",
      "Thy love is better than high birth to me,\n",
      "Richer than wealth, prouder than garments’ costs,\n",
      "Of more delight than hawks and horses be:\n",
      "And having thee, of all men’s pride I boast.\n",
      "  Wretched in this alone, that thou mayst take,\n",
      "  All this away, and me most wretched make.\n",
      "\n",
      "\n",
      "                    92\n",
      "\n",
      "But do thy worst to steal thyself away,\n",
      "For term of life thou art assured mine,\n",
      "And life no longer than thy love will stay,\n",
      "For it depends upon that love of thine.\n",
      "Then need I not to fear the worst of wrongs,\n",
      "When in the least of them my life hath end,\n",
      "I see, a better state to me belongs\n",
      "Than that, which on thy humour doth depend.\n",
      "Thou canst not vex me with inconstant mind,\n",
      "Since that my life on thy revolt doth lie,\n",
      "O what a happy title do I find,\n",
      "Happy to have thy love, hap\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Generate sequences of 32 characters and the next character as the target\n",
    "def generate_sequences(text, char_to_index, sequence_length=32, stride=1):\n",
    "    input_sequences = []\n",
    "    target_characters = []\n",
    "\n",
    "    # for i in range(0, len(text) - sequence_length, stride):\n",
    "    for i in tqdm(range(0, len(text) - sequence_length - 1, stride), desc=\"Generating sequences\"):\n",
    "        input_seq = text[i:i+sequence_length]\n",
    "        # Target/next character\n",
    "        target_char = text[i+sequence_length]\n",
    "\n",
    "        # Convert input sequence to one-hot encoded vectors\n",
    "        input_seq_encoded = [one_hot_encode(c, char_to_index, len(char_to_index)) for c in input_seq]\n",
    "        input_sequences.append(input_seq_encoded)\n",
    "\n",
    "        # One-hot encoding for the target character\n",
    "        target_char_encoded = one_hot_encode(target_char, char_to_index, len(char_to_index))\n",
    "        target_characters.append(target_char_encoded)\n",
    "\n",
    "    return np.array(input_sequences), np.array(target_characters)\n"
   ],
   "id": "da41e402067fbaf5"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b61dfa3f256a14a8",
    "outputId": "b88f80aa-823f-48d0-b5d4-3322bb313126",
    "ExecuteTime": {
     "end_time": "2024-11-02T21:16:13.478857Z",
     "start_time": "2024-11-02T21:16:13.463224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_sequences, target_characters = generate_sequences(text, char_to_index)\n",
    "print(f\"Input sequences shape: {input_sequences.shape}\")\n",
    "print(f\"Target characters shape: {target_characters.shape}\")\n",
    "print(input_sequences[2])\n",
    "print(target_characters[35])"
   ],
   "id": "b61dfa3f256a14a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b61aff6c6ca7909",
    "outputId": "c9a4ddaa-39c9-4fb7-cf16-2b90e015c042",
    "ExecuteTime": {
     "end_time": "2024-11-02T21:16:17.800219Z",
     "start_time": "2024-11-02T21:16:14.234768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, dropout=0.2):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return F.log_softmax(out, dim=1), hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, hidden_size)\n"
   ],
   "id": "6b61aff6c6ca7909",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:17:35.818144Z",
     "start_time": "2024-11-02T21:17:30.656398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load text and prepare data\n",
    "text = text_list[0]\n",
    "vocab_size, unique_chars = vocab_size_list[0], unique_chars_list[0]\n",
    "char_to_index, index_to_char = create_char_mappings(unique_chars)\n",
    "\n",
    "# Generate sequences\n",
    "input_sequences, target_characters = generate_sequences(text, char_to_index, stride=64)\n",
    "input_sequences = torch.tensor(input_sequences, dtype=torch.float32)  # Presuming these are one-hot encoded or normalized sequences\n",
    "target_characters = torch.tensor(target_characters, dtype=torch.long)\n",
    "\n",
    "# Create TensorDataset and DataLoader\n",
    "dataset = TensorDataset(input_sequences, target_characters)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(\"Input sequences shape:\", input_sequences.shape)\n",
    "print(\"Target characters shape:\", target_characters.shape)"
   ],
   "id": "2b2895b85ad94231",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences: 100%|██████████| 84042/84042 [00:02<00:00, 33853.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences shape: torch.Size([84042, 32, 107])\n",
      "Target characters shape: torch.Size([84042, 107])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "4c3b38fd80144a4c",
    "outputId": "bc040813-dedc-4488-9e61-21e68017c642",
    "ExecuteTime": {
     "end_time": "2024-11-02T21:13:13.171702Z",
     "start_time": "2024-11-02T21:11:37.379127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 256\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "dropout = 0.5\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = CharRNN(vocab_size, hidden_size, dropout).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for input_seqs, target_seqs in train_loader:\n",
    "        input_seqs, target_seqs = input_seqs.to(device), target_seqs.to(device)  # Move tensors to the correct device\n",
    "        hidden = model.init_hidden(batch_size).to(device)  # Move hidden state to the correct device\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(input_seqs, hidden)\n",
    "        print(\"Output shape:\", output.shape)\n",
    "        print(\"Target shape:\", target_seqs.shape)\n",
    "        loss = criterion(output.transpose(1, 2), target_seqs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for input_seqs, target_seqs in val_loader:\n",
    "            input_seqs, target_seqs = input_seqs.to(device), target_seqs.to(device)  # Move tensors to the correct device\n",
    "            hidden = model.init_hidden(batch_size).to(device)  # Move hidden state to the correct device\n",
    "            output, hidden = model(input_seqs, hidden)\n",
    "            val_loss += criterion(output.transpose(1, 2), target_seqs).item()\n",
    "        print(f'Validation Loss: {val_loss / len(val_loader)}')\n"
   ],
   "id": "4c3b38fd80144a4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([64, 32, 107])\n",
      "Target shape: torch.Size([64, 107])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e15034fe99745122",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
