{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as thv\n",
    "import os\n",
    "import pickle\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "def get_mnist_dataset(root='./mnist_data'):\n",
    "    # Check if the dataset already exists locally\n",
    "    if os.path.exists(f'{root}/train_data.pkl') and os.path.exists(f'{root}/val_data.pkl'):\n",
    "        print(\"Loading MNIST dataset from local storage...\")\n",
    "        with open(f'{root}/train_data.pkl', 'rb') as f:\n",
    "            train = pickle.load(f)\n",
    "        with open(f'{root}/val_data.pkl', 'rb') as f:\n",
    "            val = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Downloading MNIST dataset...\")\n",
    "        # Download the dataset\n",
    "        train = thv.datasets.MNIST(root, download=True, train=True)\n",
    "        val = thv.datasets.MNIST(root, download=True, train=False)\n",
    "        \n",
    "        # Save the dataset locally\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "        with open(f'{root}/train_data.pkl', 'wb') as f:\n",
    "            pickle.dump(train, f)\n",
    "        with open(f'{root}/val_data.pkl', 'wb') as f:\n",
    "            pickle.dump(val, f)\n",
    "\n",
    "    print(f\"Training dataset shape: {train.data.shape}, Number of targets: {len(train.targets)}\")\n",
    "    print(f\"Validation dataset shape: {val.data.shape}, Number of targets: {len(val.targets)}\")\n",
    "\n",
    "    return train, val\n",
    "    \n",
    "def split_dataset(train, val):\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from torch.utils.data import Subset\n",
    "\n",
    "    # Define the number of classes and target sizes\n",
    "    num_classes = 10\n",
    "    target_train_size = 30000\n",
    "    target_val_size = 5000\n",
    "\n",
    "    # Initialize lists to hold the indices for the refined datasets\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Iterate over each class and collect indices for the split\n",
    "    for i in range(num_classes):\n",
    "        # Get indices of all examples from class i in the training and validation sets\n",
    "        train_class_indices = (train.targets == i).nonzero(as_tuple=True)[0]\n",
    "        val_class_indices = (val.targets == i).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        # Convert indices to numpy arrays for shuffling\n",
    "        train_class_indices_np = train_class_indices.numpy()\n",
    "        val_class_indices_np = val_class_indices.numpy()\n",
    "\n",
    "        # Shuffle indices\n",
    "        np.random.shuffle(train_class_indices_np)\n",
    "        np.random.shuffle(val_class_indices_np)\n",
    "\n",
    "        # Calculate split indices, initially aiming to round up\n",
    "        split_idx_train = (len(train_class_indices_np) + 1) // 2\n",
    "        split_idx_val = (len(val_class_indices_np) + 1) // 2\n",
    "\n",
    "        # Adjust split to avoid exceeding overall target sizes\n",
    "        if len(train_indices) + split_idx_train > target_train_size:\n",
    "            split_idx_train = target_train_size - len(train_indices)\n",
    "        if len(val_indices) + split_idx_val > target_val_size:\n",
    "            split_idx_val = target_val_size - len(val_indices)\n",
    "\n",
    "        # Add indices to lists\n",
    "        train_indices.extend(train_class_indices_np[:split_idx_train])\n",
    "        val_indices.extend(val_class_indices_np[:split_idx_val])\n",
    "\n",
    "        # Check if we have already reached the target sizes\n",
    "        if len(train_indices) == target_train_size and len(val_indices) == target_val_size:\n",
    "            break\n",
    "\n",
    "    # Create refined datasets\n",
    "    refined_train = Subset(train, train_indices)\n",
    "    refined_val = Subset(val, val_indices)\n",
    "\n",
    "    print(f\"Refined training dataset size: {len(refined_train)}\")\n",
    "    print(f\"Refined validation dataset size: {len(refined_val)}\")\n",
    "\n",
    "    return refined_train, refined_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset from local storage...\n",
      "Training dataset shape: torch.Size([60000, 28, 28]), Number of targets: 60000\n",
      "Validation dataset shape: torch.Size([10000, 28, 28]), Number of targets: 10000\n",
      "Refined training dataset size: 30000\n",
      "Refined validation dataset size: 5000\n",
      "Train Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./prob3_mnist_data\n",
      "    Split: Train\n",
      "Val Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./prob3_mnist_data\n",
      "    Split: Test\n",
      "Refined Train <torch.utils.data.dataset.Subset object at 0x000001E70EB10C10>\n",
      "Refined Val <torch.utils.data.dataset.Subset object at 0x000001E70EB103D0>\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./prob3_mnist_data\"\n",
    "\n",
    "train, val = get_mnist_dataset(data_path)\n",
    "refined_train, refined_val = split_dataset(train, val)\n",
    "\n",
    "print(\"Train\", train)\n",
    "print(\"Val\", val)\n",
    "print(\"Refined Train\", refined_train)\n",
    "print(\"Refined Val\", refined_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def plot_images(dataset, num_images=6):\n",
    "    # Making sure the dataset can be indexed directly\n",
    "    assert hasattr(dataset, '__getitem__'), \"Dataset must support indexing\"\n",
    "\n",
    "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 2, 3))\n",
    "    \n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, idx in zip(axes, indices):\n",
    "        image, label = dataset[idx]\n",
    "        \n",
    "        # MNIST images are 1-channel images, need to be reshaped if in tensor form\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.numpy().squeeze()  # Convert to numpy and remove extra dimensions\n",
    "        \n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title(f\"Label: {label}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_images(refined_train, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_t:\n",
    "    def __init__(self):\n",
    "        # initialize to appropriate sizes, fill with Gaussian entires\n",
    "        # normalize to make the Frobenius norm of w, b equal to 1\n",
    "        self.w, self.b = ...\n",
    "\n",
    "    def forward(self, h^l):\n",
    "        h^{l+1} = ...\n",
    "        # cache h^l in forward because we will need it to compute\n",
    "        # dw in backward\n",
    "        self.hl = h^l\n",
    "        return h^{l+1}\n",
    "\n",
    "    def backward(self, dh^{l+1}):\n",
    "        dh^l, dw, db = ...\n",
    "        self.dw, self.db = dw, db\n",
    "        # notice that there is no need to cache dh^l\n",
    "        return dh^l\n",
    "\n",
    "    def zero_grad(self):\n",
    "        # useful to delete the stored backprop gradients of the\n",
    "        # previous mini -batch before you start a new mini -batch\n",
    "        self.dw, self.db = 0*self.dw, 0*self.db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
