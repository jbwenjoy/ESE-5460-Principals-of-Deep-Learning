{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB7znsvhyuRH",
        "ExecuteTime": {
          "end_time": "2024-10-21T02:29:44.857102Z",
          "start_time": "2024-10-21T02:29:40.350511Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e808ad0e-a04f-494f-a08e-a248007159f3"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "dir_root = ''\n",
        "# If using google colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    dir_root = '/content/drive/MyDrive/Colab Notebooks/ESE546/hw2'\n",
        "\n",
        "print(dir_root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgxQU-uu_DWc",
        "outputId": "569d46ab-222b-40bd-e08d-f15d6632fa6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/Colab Notebooks/ESE546/hw2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI6XEXSGyYkh"
      },
      "source": [
        "### (a) Plot the training and validation losses and errors as a function of the number of epochs\n",
        "\n",
        "\n",
        " The model currently does not achieve less than 12% validation error, you have to tweak the parameters to get it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaNQQai_wON0",
        "outputId": "6cba990a-cdc3-4025-d14d-d5b6e2dc92cc",
        "ExecuteTime": {
          "end_time": "2024-10-21T02:29:49.300111Z",
          "start_time": "2024-10-21T02:29:48.303116Z"
        }
      },
      "source": [
        "# Define the dataset directory\n",
        "data_dir = os.path.join(dir_root, 'data')\n",
        "print(data_dir)\n",
        "\n",
        "if not os.path.exists(os.path.join(data_dir, 'cifar-10-batches-py')):\n",
        "    download = True\n",
        "    print('Dataset not found, downloading...')\n",
        "else:\n",
        "    download = False\n",
        "    print('Dataset found, not downloading.')\n",
        "\n",
        "# Reading in the dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True,\n",
        "                                        download=download, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False,\n",
        "                                       download=download, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# Defining the model\n",
        "class View(nn.Module):\n",
        "    def __init__(self,o):\n",
        "        super().__init__()\n",
        "        self.o = o\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x.view(-1, self.o)\n",
        "\n",
        "class allcnn_t(nn.Module):\n",
        "    def __init__(self, c1=96, c2= 192):\n",
        "        super().__init__()\n",
        "        d = 0.5\n",
        "\n",
        "        def convbn(ci,co,ksz,s=1,pz=0):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm2d(co))\n",
        "\n",
        "        self.m = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            convbn(3,c1,3,1,1),\n",
        "            convbn(c1,c1,3,1,1),\n",
        "            convbn(c1,c1,3,2,1),\n",
        "            nn.Dropout(d),\n",
        "            convbn(c1,c2,3,1,1),\n",
        "            convbn(c2,c2,3,1,1),\n",
        "            convbn(c2,c2,3,2,1),\n",
        "            nn.Dropout(d),\n",
        "            convbn(c2,c2,3,1,1),\n",
        "            convbn(c2,c2,3,1,1),\n",
        "            convbn(c2,10,1,1),\n",
        "            nn.AvgPool2d(8),\n",
        "            View(10))\n",
        "\n",
        "        print('Num parameters: ', sum([p.numel() for p in self.m.parameters()]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.m(x)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ESE546/hw2/data\n",
            "Dataset found, not downloading.\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-21T02:29:50.781606Z",
          "start_time": "2024-10-21T02:29:50.526768Z"
        },
        "id": "SIPA6kWl-1r5"
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Initialize the logger\n",
        "logger = SummaryWriter(os.path.join(dir_root, 'runs/cnn_experiment'))"
      ],
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34JavUIgRpcP",
        "ExecuteTime": {
          "end_time": "2024-10-21T02:29:51.610243Z",
          "start_time": "2024-10-21T02:29:51.594618Z"
        }
      },
      "source": [
        "# # The training loop for 50 epochs\n",
        "\n",
        "# def train(net, optimizer, criterion, train_loader, test_loader, epochs, model_name, plot):\n",
        "#     model = net.to(device)\n",
        "#     total_step = len(train_loader)\n",
        "#     overall_step = 0\n",
        "#     train_loss_values = []\n",
        "#     train_error = []\n",
        "#     val_loss_values = []\n",
        "#     val_error = []\n",
        "#     for epoch in range(epochs):\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "#         flag = 0\n",
        "#         running_loss = 0.0\n",
        "#         if epoch == 25 and flag == 0:\n",
        "#           for op_params in optimizer.param_groups:\n",
        "#             op_params['lr'] = 0.001\n",
        "#           flag = 1\n",
        "#         for i, (images, labels) in enumerate(train_loader):\n",
        "#             # Move tensors to configured device\n",
        "#             images = images.to(device)\n",
        "#             labels = labels.to(device)\n",
        "#             #Forward Pass\n",
        "#             outputs = model(images)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             running_loss += loss.item()\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "#             total += labels.size(0)\n",
        "#             correct += (predicted == labels).sum().item()\n",
        "#             optimizer.step()\n",
        "#             if (i+1) % 1000 == 0:\n",
        "#               print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))\n",
        "#             if plot:\n",
        "#               info = { ('loss_' + model_name): loss.item() }\n",
        "\n",
        "#               for tag, value in info.items():\n",
        "#                 logger.add_scalar(tag, value, overall_step+1)\n",
        "#         train_loss_values.append(running_loss)\n",
        "#         train_error.append(100-100*correct/total)\n",
        "\n",
        "#         model.eval()\n",
        "#         with torch.no_grad():\n",
        "#             correct = 0\n",
        "#             total = 0\n",
        "#             for i, (images, labels) in enumerate(test_loader):\n",
        "#                 images = images.to(device)\n",
        "#                 labels = labels.to(device)\n",
        "#                 outputs = model(images)\n",
        "#                 _, predicted = torch.max(outputs.data, 1)\n",
        "#                 total += labels.size(0)\n",
        "#                 correct += (predicted == labels).sum().item()\n",
        "\n",
        "#         print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))\n",
        "#         val_error.append(100-100*correct/total)\n",
        "#         val_loss_values.append(running_loss)\n",
        "#     return val_error,val_loss_values,train_error,train_loss_values\n"
      ],
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7YvtAlERz61",
        "ExecuteTime": {
          "end_time": "2024-10-21T02:29:52.658950Z",
          "start_time": "2024-10-21T02:29:52.627681Z"
        }
      },
      "source": [
        "# model_path_50 = os.path.join(dir_root, 'runs/hw2p3_model_1_50_epoch.pt')\n",
        "\n",
        "# if not os.path.exists(model_path_50):\n",
        "#     model = allcnn_t().to(device)\n",
        "#     epochs = 50\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001, nesterov=True)\n",
        "#     val_error, val_loss_values, train_error, train_loss_values = train(model, optimizer, criterion, trainloader, testloader, epochs, 'cnn_curve', True)\n",
        "#     torch.save(model, model_path_50)\n",
        "# else:\n",
        "#     print(f\"Model already exists at {model_path_50}, skipping training.\")"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-21T02:45:38.963082Z",
          "start_time": "2024-10-21T02:45:38.947443Z"
        },
        "id": "Rn6i1OER-1r6"
      },
      "cell_type": "code",
      "source": [
        "# Training 100 epochs using the same configuration, except that:\n",
        "# Learning rate of 0.1 for the first 40 epochs, then 0.01 for the next 40 epochs\n",
        "# and then 0.001 for the final 20 epochs.\n",
        "# Weight decay = 1e-3\n",
        "# SGD with Nesterov’s momentum of 0.9\n",
        "# Plot the training and validation losses and errors with the number of epochs\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, lr_array):\n",
        "    if epoch < 40:\n",
        "        lr = lr_array[0]\n",
        "    elif epoch < 80:\n",
        "        lr = lr_array[1]\n",
        "    else:\n",
        "        lr = lr_array[2]\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def train(net, optimizer, criterion, train_loader, test_loader, epochs, model_name, plot, scheduled_lr_array):\n",
        "    model = net.to(device)\n",
        "    total_step = len(train_loader)\n",
        "    overall_step = 0\n",
        "    train_loss_values = []\n",
        "    train_error = []\n",
        "    val_loss_values = []\n",
        "    val_error = []\n",
        "    for epoch in range(epochs):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        flag = 0\n",
        "        running_loss = 0.0\n",
        "\n",
        "        adjust_learning_rate(optimizer, epoch, scheduled_lr_array)\n",
        "        print(f\"Epoch {epoch+1}, Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # Move tensors to configured device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            optimizer.step()\n",
        "            if (i+1) % 1000 == 0:\n",
        "              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))\n",
        "            if plot:\n",
        "              info = { ('loss_' + model_name): loss.item() }\n",
        "\n",
        "              for tag, value in info.items():\n",
        "                logger.add_scalar(tag, value, overall_step+1)\n",
        "        train_loss_values.append(running_loss)\n",
        "        train_error.append(100 - 100 * correct / total)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for i, (images, labels) in enumerate(test_loader):\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))\n",
        "        val_error.append(100-100*correct/total)\n",
        "        val_loss_values.append(running_loss)\n",
        "    return val_error,val_loss_values,train_error,train_loss_values\n"
      ],
      "outputs": [],
      "execution_count": 7
    },
    {
      "metadata": {
        "jupyter": {
          "is_executing": true
        },
        "ExecuteTime": {
          "start_time": "2024-10-21T02:45:39.535161Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnlu543E-1r7",
        "outputId": "01e9f043-8197-48fd-bf6d-db5bedf61fb5"
      },
      "cell_type": "code",
      "source": [
        "model_path_100 = os.path.join(dir_root, 'runs/hw2p3_model_100_epoch.pt')\n",
        "\n",
        "TRAIN_FLAG = True\n",
        "\n",
        "if not os.path.exists(model_path_100) or TRAIN_FLAG:\n",
        "    model = allcnn_t().to(device)\n",
        "    epochs = 100\n",
        "    scheduled_lr = [0.5, 0.007, 0.0005]\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.001, nesterov=True)\n",
        "\n",
        "    val_error, val_loss_values, train_error, train_loss_values = train(model, optimizer, criterion, trainloader, testloader, epochs, 'cnn_curve_100', True, scheduled_lr)\n",
        "\n",
        "    torch.save(model, model_path_100)\n",
        "\n",
        "    np.save(os.path.join(dir_root, 'runs/train_error_100.npy'), np.array(train_error))\n",
        "    np.save(os.path.join(dir_root, 'runs/train_loss_values_100.npy'), np.array(train_loss_values))\n",
        "    np.save(os.path.join(dir_root, 'runs/val_error_100.npy'), np.array(val_error))\n",
        "    np.save(os.path.join(dir_root, 'runs/val_loss_values_100.npy'), np.array(val_loss_values))\n",
        "else:\n",
        "    print(f\"Model already exists at {model_path_100}, skipping training.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num parameters:  1667166\n",
            "Epoch 1, Learning Rate: 0.5\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "m4nFu-md-1r7"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Plot the training and validation losses and errors with the number of epochs\n",
        "# First load the saved data\n",
        "if os.path.exists(model_path_100) and not TRAIN_FLAG:\n",
        "    train_error = np.load(os.path.join(dir_root, 'runs/train_error_100.npy'))\n",
        "    train_loss_values = np.load(os.path.join(dir_root, 'runs/train_loss_values_100.npy'))\n",
        "    val_error = np.load(os.path.join(dir_root, 'runs/val_error_100.npy'))\n",
        "    val_loss_values = np.load(os.path.join(dir_root, 'runs/val_loss_values_100.npy'))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(np.array(train_loss_values), label='Training Loss')\n",
        "plt.plot(np.array(val_loss_values), label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(np.array(train_error), label='Training Error')\n",
        "plt.plot(np.array(val_error), label='Validation Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error (%)')\n",
        "plt.title('Training and Validation Error')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically shutdown Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()\n"
      ],
      "metadata": {
        "id": "ixLHJATeTj4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}