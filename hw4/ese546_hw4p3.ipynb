{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:13:59.606902Z",
     "start_time": "2024-11-26T18:13:55.194049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys, subprocess, json, argparse\n",
    "from itertools import product\n"
   ],
   "id": "9107cce774b4dc37",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:14:01.020921Z",
     "start_time": "2024-11-26T18:14:00.280576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)\n",
    "\n",
    "dir_root = ''\n",
    "# If using google colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    dir_root = '/content/drive/MyDrive/Colab Notebooks/ESE546/hw4'\n",
    "\n",
    "print(\"dir_root:\", dir_root)"
   ],
   "id": "1a450805ac6a98a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "dir_root: \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:14:02.798884Z",
     "start_time": "2024-11-26T18:14:01.866807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the dataset directory\n",
    "data_dir = os.path.join(dir_root, 'data')\n",
    "print(data_dir)\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, 'cifar-10-batches-py')):\n",
    "    download = True\n",
    "    print('Dataset not found, downloading...')\n",
    "else:\n",
    "    download = False\n",
    "    print('Dataset found, not downloading.')\n",
    "\n",
    "# Reading in the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True,\n",
    "                                        download=download, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False,\n",
    "                                       download=download, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "id": "c599442d8304e9e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "Dataset found, not downloading.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:14:04.419503Z",
     "start_time": "2024-11-26T18:14:04.399515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# File allcnn.py provided by Prof. Pratik Chaudhari\n",
    "# at https://gist.github.com/pratikac/68d6d94e4739786798e90691fb1a581b\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, o):\n",
    "        super().__init__()\n",
    "        self.o = o\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, self.o)\n",
    "\n",
    "class allcnn_t(nn.Module):\n",
    "    def __init__(self, c1=96, c2=192):\n",
    "        super().__init__()\n",
    "        d = 0.5\n",
    "\n",
    "        def convbn(ci, co, ksz, s=1, pz=0):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(ci, co, ksz, stride=s, padding=pz),\n",
    "                nn.ReLU(True),\n",
    "                nn.BatchNorm2d(co))\n",
    "\n",
    "        self.m = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            convbn(3, c1, 3, 1, 1),\n",
    "            convbn(c1, c1, 3, 1, 1),\n",
    "            convbn(c1, c1, 3, 2, 1),\n",
    "            nn.Dropout(d),\n",
    "            convbn(c1, c2, 3, 1, 1),\n",
    "            convbn(c2, c2, 3, 1, 1),\n",
    "            convbn(c2, c2, 3, 2, 1),\n",
    "            nn.Dropout(d),\n",
    "            convbn(c2, c2, 3, 1, 1),\n",
    "            convbn(c2, c2, 3, 1, 1),\n",
    "            convbn(c2, 10, 1, 1),\n",
    "            nn.AvgPool2d(8),\n",
    "            View(10))\n",
    "\n",
    "        print('Num parameters: ', sum([p.numel() for p in self.m.parameters()]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n"
   ],
   "id": "73a904e76d2d9a97",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:16:56.097931Z",
     "start_time": "2024-11-26T18:16:56.077926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Weight decay = 1e-3\n",
    "# SGD with Nesterov’s momentum of 0.9\n",
    "# Dropout = 0.5\n",
    "# Learning rate starts with eta_0 = 1e-5,\n",
    "# then eta_tp1 = 1.1 * eta_t, (t <= 100)\n",
    "\n",
    "# First train 100 iters\n",
    "# Record the average training loss of each mini-batch separately and the learning rate that was used for it for about 100 iterations. \n",
    "# Plot the training loss (Y-axis) as a function of the learning rate (X-axis); use a log-scale for the X-axis.\n",
    "\n",
    "# Initialize the logger\n",
    "logger = SummaryWriter(os.path.join(dir_root, 'runs/cnn_experiment'))\n",
    "\n",
    "def train(net, optimizer, criterion, train_loader, test_loader, epochs, model_name, plot):\n",
    "    model = net.to(device)\n",
    "    total_step = len(train_loader)\n",
    "    overall_step = 0\n",
    "    train_loss_values = []\n",
    "    train_error = []\n",
    "    val_loss_values = []\n",
    "    val_error = []\n",
    "    learning_rates = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        flag = 0\n",
    "        running_loss = 0.0\n",
    "        learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move tensors to configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i+1) % 1000 == 0:\n",
    "              print ('Epoch [{}/{}], Step [{}/{}], Learning Rate: {:.3g}, Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, optimizer.param_groups[0]['lr'], loss.item()))\n",
    "            if plot:\n",
    "              info = { ('loss_' + model_name): loss.item() }\n",
    "\n",
    "              for tag, value in info.items():\n",
    "                logger.add_scalar(tag, value, overall_step+1)\n",
    "\n",
    "        # Update learning rate every epoch\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 1.1         \n",
    "        \n",
    "        train_loss_values.append(running_loss)\n",
    "        train_error.append(100 - 100 * correct / total)\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i, (images, labels) in enumerate(test_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))\n",
    "        val_error.append(100 - 100 * correct / total)\n",
    "        val_loss_values.append(val_running_loss)\n",
    "    return val_error, val_loss_values, train_error, train_loss_values\n"
   ],
   "id": "d7f37b7c635c4283",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:33:02.255065Z",
     "start_time": "2024-11-26T18:16:57.816169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Weight decay = 1e-3\n",
    "# SGD with Nesterov’s momentum of 0.9\n",
    "# Dropout = 0.5\n",
    "# Learning rate starts with eta_0 = 1e-5,\n",
    "# then eta_tp1 = 1.1 * eta_t, (t <= 100)\n",
    "\n",
    "model_path_100 = os.path.join(dir_root, 'runs/hw4p3_model_100_epoch.pt')\n",
    "\n",
    "TRAIN_FLAG = True\n",
    "\n",
    "if not os.path.exists(model_path_100) or TRAIN_FLAG:\n",
    "    model = allcnn_t().to(device)\n",
    "    epochs = 100\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-5, momentum=0.9, weight_decay=1e-3, nesterov=True)\n",
    "\n",
    "    val_error, val_loss_values, train_error, train_loss_values = train(model, optimizer, criterion, trainloader, testloader, epochs, 'cnn_curve_100', True)\n",
    "\n",
    "    torch.save(model, model_path_100)\n",
    "\n",
    "    np.save(os.path.join(dir_root, 'runs/train_error_100.npy'), np.array(train_error))\n",
    "    np.save(os.path.join(dir_root, 'runs/train_loss_values_100.npy'), np.array(train_loss_values))\n",
    "    np.save(os.path.join(dir_root, 'runs/val_error_100.npy'), np.array(val_error))\n",
    "    np.save(os.path.join(dir_root, 'runs/val_loss_values_100.npy'), np.array(val_loss_values))\n",
    "else:\n",
    "    print(f\"Model already exists at {model_path_100}, skipping training.\")"
   ],
   "id": "71255eb6cdf29300",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters:  1667166\n",
      "Epoch [1/100], Step [1000/3125], Learning Rate: 1e-05, Loss: 2.2272\n",
      "Epoch [1/100], Step [2000/3125], Learning Rate: 1e-05, Loss: 2.1947\n",
      "Epoch [1/100], Step [3000/3125], Learning Rate: 1e-05, Loss: 2.0731\n",
      "Accuracy of the network on the test images: 16.71 %\n",
      "Epoch [2/100], Step [1000/3125], Learning Rate: 1.1e-05, Loss: 1.3452\n",
      "Epoch [2/100], Step [2000/3125], Learning Rate: 1.1e-05, Loss: 1.4065\n",
      "Epoch [2/100], Step [3000/3125], Learning Rate: 1.1e-05, Loss: 2.0390\n",
      "Accuracy of the network on the test images: 39.73 %\n",
      "Epoch [3/100], Step [1000/3125], Learning Rate: 1.21e-05, Loss: 1.7353\n",
      "Epoch [3/100], Step [2000/3125], Learning Rate: 1.21e-05, Loss: 1.7695\n",
      "Epoch [3/100], Step [3000/3125], Learning Rate: 1.21e-05, Loss: 1.6072\n",
      "Accuracy of the network on the test images: 44.89 %\n",
      "Epoch [4/100], Step [1000/3125], Learning Rate: 1.33e-05, Loss: 1.6267\n",
      "Epoch [4/100], Step [2000/3125], Learning Rate: 1.33e-05, Loss: 1.0896\n",
      "Epoch [4/100], Step [3000/3125], Learning Rate: 1.33e-05, Loss: 1.2947\n",
      "Accuracy of the network on the test images: 49.39 %\n",
      "Epoch [5/100], Step [1000/3125], Learning Rate: 1.46e-05, Loss: 1.4525\n",
      "Epoch [5/100], Step [2000/3125], Learning Rate: 1.46e-05, Loss: 1.3050\n",
      "Epoch [5/100], Step [3000/3125], Learning Rate: 1.46e-05, Loss: 1.4950\n",
      "Accuracy of the network on the test images: 51.77 %\n",
      "Epoch [6/100], Step [1000/3125], Learning Rate: 1.61e-05, Loss: 0.9441\n",
      "Epoch [6/100], Step [2000/3125], Learning Rate: 1.61e-05, Loss: 0.8579\n",
      "Epoch [6/100], Step [3000/3125], Learning Rate: 1.61e-05, Loss: 1.5634\n",
      "Accuracy of the network on the test images: 54.41 %\n",
      "Epoch [7/100], Step [1000/3125], Learning Rate: 1.77e-05, Loss: 0.7181\n",
      "Epoch [7/100], Step [2000/3125], Learning Rate: 1.77e-05, Loss: 1.4718\n",
      "Epoch [7/100], Step [3000/3125], Learning Rate: 1.77e-05, Loss: 0.7329\n",
      "Accuracy of the network on the test images: 57.02 %\n",
      "Epoch [8/100], Step [1000/3125], Learning Rate: 1.95e-05, Loss: 1.1961\n",
      "Epoch [8/100], Step [2000/3125], Learning Rate: 1.95e-05, Loss: 0.7927\n",
      "Epoch [8/100], Step [3000/3125], Learning Rate: 1.95e-05, Loss: 0.8795\n",
      "Accuracy of the network on the test images: 60.33 %\n",
      "Epoch [9/100], Step [1000/3125], Learning Rate: 2.14e-05, Loss: 1.1964\n",
      "Epoch [9/100], Step [2000/3125], Learning Rate: 2.14e-05, Loss: 1.0282\n",
      "Epoch [9/100], Step [3000/3125], Learning Rate: 2.14e-05, Loss: 1.0213\n",
      "Accuracy of the network on the test images: 62.14 %\n",
      "Epoch [10/100], Step [1000/3125], Learning Rate: 2.36e-05, Loss: 1.6069\n",
      "Epoch [10/100], Step [2000/3125], Learning Rate: 2.36e-05, Loss: 0.6455\n",
      "Epoch [10/100], Step [3000/3125], Learning Rate: 2.36e-05, Loss: 0.7702\n",
      "Accuracy of the network on the test images: 64.51 %\n",
      "Epoch [11/100], Step [1000/3125], Learning Rate: 2.59e-05, Loss: 0.8124\n",
      "Epoch [11/100], Step [2000/3125], Learning Rate: 2.59e-05, Loss: 1.0218\n",
      "Epoch [11/100], Step [3000/3125], Learning Rate: 2.59e-05, Loss: 0.6080\n",
      "Accuracy of the network on the test images: 64.35 %\n",
      "Epoch [12/100], Step [1000/3125], Learning Rate: 2.85e-05, Loss: 0.6592\n",
      "Epoch [12/100], Step [2000/3125], Learning Rate: 2.85e-05, Loss: 0.5621\n",
      "Epoch [12/100], Step [3000/3125], Learning Rate: 2.85e-05, Loss: 1.1857\n",
      "Accuracy of the network on the test images: 66.95 %\n",
      "Epoch [13/100], Step [1000/3125], Learning Rate: 3.14e-05, Loss: 1.4708\n",
      "Epoch [13/100], Step [2000/3125], Learning Rate: 3.14e-05, Loss: 0.6661\n",
      "Epoch [13/100], Step [3000/3125], Learning Rate: 3.14e-05, Loss: 0.8893\n",
      "Accuracy of the network on the test images: 67.85 %\n",
      "Epoch [14/100], Step [1000/3125], Learning Rate: 3.45e-05, Loss: 0.7461\n",
      "Epoch [14/100], Step [2000/3125], Learning Rate: 3.45e-05, Loss: 1.2250\n",
      "Epoch [14/100], Step [3000/3125], Learning Rate: 3.45e-05, Loss: 0.5013\n",
      "Accuracy of the network on the test images: 69.54 %\n",
      "Epoch [15/100], Step [1000/3125], Learning Rate: 3.8e-05, Loss: 0.5000\n",
      "Epoch [15/100], Step [2000/3125], Learning Rate: 3.8e-05, Loss: 0.8824\n",
      "Epoch [15/100], Step [3000/3125], Learning Rate: 3.8e-05, Loss: 1.4730\n",
      "Accuracy of the network on the test images: 67.93 %\n",
      "Epoch [16/100], Step [1000/3125], Learning Rate: 4.18e-05, Loss: 0.7351\n",
      "Epoch [16/100], Step [2000/3125], Learning Rate: 4.18e-05, Loss: 0.4286\n",
      "Epoch [16/100], Step [3000/3125], Learning Rate: 4.18e-05, Loss: 0.5035\n",
      "Accuracy of the network on the test images: 72.47 %\n",
      "Epoch [17/100], Step [1000/3125], Learning Rate: 4.59e-05, Loss: 0.8882\n",
      "Epoch [17/100], Step [2000/3125], Learning Rate: 4.59e-05, Loss: 0.4939\n",
      "Epoch [17/100], Step [3000/3125], Learning Rate: 4.59e-05, Loss: 0.5088\n",
      "Accuracy of the network on the test images: 71.98 %\n",
      "Epoch [18/100], Step [1000/3125], Learning Rate: 5.05e-05, Loss: 0.2943\n",
      "Epoch [18/100], Step [2000/3125], Learning Rate: 5.05e-05, Loss: 0.4638\n",
      "Epoch [18/100], Step [3000/3125], Learning Rate: 5.05e-05, Loss: 0.2605\n",
      "Accuracy of the network on the test images: 73.85 %\n",
      "Epoch [19/100], Step [1000/3125], Learning Rate: 5.56e-05, Loss: 0.5169\n",
      "Epoch [19/100], Step [2000/3125], Learning Rate: 5.56e-05, Loss: 0.5549\n",
      "Epoch [19/100], Step [3000/3125], Learning Rate: 5.56e-05, Loss: 0.3943\n",
      "Accuracy of the network on the test images: 73.66 %\n",
      "Epoch [20/100], Step [1000/3125], Learning Rate: 6.12e-05, Loss: 0.2237\n",
      "Epoch [20/100], Step [2000/3125], Learning Rate: 6.12e-05, Loss: 0.4307\n",
      "Epoch [20/100], Step [3000/3125], Learning Rate: 6.12e-05, Loss: 0.6224\n",
      "Accuracy of the network on the test images: 75.12 %\n",
      "Epoch [21/100], Step [1000/3125], Learning Rate: 6.73e-05, Loss: 0.3792\n",
      "Epoch [21/100], Step [2000/3125], Learning Rate: 6.73e-05, Loss: 0.1356\n",
      "Epoch [21/100], Step [3000/3125], Learning Rate: 6.73e-05, Loss: 0.5379\n",
      "Accuracy of the network on the test images: 74.51 %\n",
      "Epoch [22/100], Step [1000/3125], Learning Rate: 7.4e-05, Loss: 0.1035\n",
      "Epoch [22/100], Step [2000/3125], Learning Rate: 7.4e-05, Loss: 0.5227\n",
      "Epoch [22/100], Step [3000/3125], Learning Rate: 7.4e-05, Loss: 0.5989\n",
      "Accuracy of the network on the test images: 74.69 %\n",
      "Epoch [23/100], Step [1000/3125], Learning Rate: 8.14e-05, Loss: 0.4620\n",
      "Epoch [23/100], Step [2000/3125], Learning Rate: 8.14e-05, Loss: 0.5152\n",
      "Epoch [23/100], Step [3000/3125], Learning Rate: 8.14e-05, Loss: 0.3930\n",
      "Accuracy of the network on the test images: 72.82 %\n",
      "Epoch [24/100], Step [1000/3125], Learning Rate: 8.95e-05, Loss: 0.0754\n",
      "Epoch [24/100], Step [2000/3125], Learning Rate: 8.95e-05, Loss: 0.4698\n",
      "Epoch [24/100], Step [3000/3125], Learning Rate: 8.95e-05, Loss: 0.1333\n",
      "Accuracy of the network on the test images: 74.06 %\n",
      "Epoch [25/100], Step [1000/3125], Learning Rate: 9.85e-05, Loss: 0.0213\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m     15\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mSGD(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m, momentum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-3\u001B[39m, nesterov\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 17\u001B[0m val_error, val_loss_values, train_error, train_loss_values \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtestloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcnn_curve_100\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model, model_path_100)\n\u001B[0;32m     21\u001B[0m np\u001B[38;5;241m.\u001B[39msave(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dir_root, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mruns/train_error_100.npy\u001B[39m\u001B[38;5;124m'\u001B[39m), np\u001B[38;5;241m.\u001B[39marray(train_error))\n",
      "Cell \u001B[1;32mIn[7], line 33\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(net, optimizer, criterion, train_loader, test_loader, epochs, model_name, plot)\u001B[0m\n\u001B[0;32m     29\u001B[0m learning_rates\u001B[38;5;241m.\u001B[39mappend(optimizer\u001B[38;5;241m.\u001B[39mparam_groups[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (images, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;66;03m# Move tensors to configured device\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m     images \u001B[38;5;241m=\u001B[39m \u001B[43mimages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;66;03m# Forward\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Then\n",
    "# Use cosine learning rate schedule with a warmup\n",
    "# \\eta(t) = 1e-4 + t / T * eta_max, if t <= T0\n",
    "# \\eta(t) = eta_max * cos(pi / 2 * (t - T0) / (T - T0)) + 1e-6, if T0 < t <= T"
   ],
   "id": "1f4e3683ebfba8b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
